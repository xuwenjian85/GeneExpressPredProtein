{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "from copy import deepcopy\n",
    "import time, os, sys\n",
    "\n",
    "from sklearn import linear_model, metrics\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import pickle\n",
    "from scipy import stats\n",
    "\n",
    "import mkl\n",
    "mkl.set_num_threads(1)\n",
    "nCPU= 30\n",
    "N=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/media/eys/xwj/proteome/data/20210926_dict_matrix_20dataset.pkl'\n",
    "with open(file, 'rb') as f:\n",
    "    [ dict_dataset, df_summary]=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "datalist = list(dict_dataset.keys())\n",
    "\n",
    "# \n",
    "model_dict = {\n",
    "    \"LR\":  linear_model.LinearRegression(),\n",
    "    \"Lasso\": linear_model.Lasso(alpha=0.02, max_iter=1e5),\n",
    "    \"HR\": linear_model.HuberRegressor(),  #Linear regression model that is robust to outliers.\n",
    "    \"Ridge\": linear_model.Ridge(),\n",
    "#     \"Bay\": linear_model.BayesianRidge(),\n",
    "    \"SVR\": SVR( gamma='scale'),\n",
    "    \"RFR\": RandomForestRegressor(n_estimators=100, max_depth=3)\n",
    "    }\n",
    "method_feature_select = [\"random\",\"cosine\",\"self\"]\n",
    "# feature numbers\n",
    "list_topn = [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 200, 1000, 5000]\n",
    "\n",
    "#############\n",
    "def create_res(list_topn):\n",
    "    res = {}\n",
    "    for mfs in method_feature_select:\n",
    "        res[mfs] = {} \n",
    "        for topn in list_topn:\n",
    "            # summary table\n",
    "            res[mfs][topn] = {}\n",
    "            res[mfs][topn][\"summary\"] = pd.DataFrame(index = model_dict , columns= \n",
    "                        [\"mae_val\",  \"rmse_val\",  \"r2_val\",   \"mae_val_mean\",  \"rmse_val_mean\", \"r2_val_mean\", \n",
    "                         \"mae_test\", \"rmse_test\",\"r2_test\", \"mae_test_mean\", \"rmse_test_mean\",\"r2_test_mean\"])\n",
    "            res[mfs][topn][\"time\"] = pd.DataFrame(data = 0, dtype = int, index = model_dict, columns= [\"val\",\"test\"])\n",
    "            # detail data for all models\n",
    "            for m in model_dict:\n",
    "                res[mfs][topn][m]={}\n",
    "                res[mfs][topn][m][\"y_pred_val\"], res[mfs][topn][m][\"y_pred_test\"] ={}, {}\n",
    "                res[mfs][topn][m][\"df_val_mae\"], res[mfs][topn][m][\"df_val_rmse\"], res[mfs][topn][m][\"df_val_r2\"], \\\n",
    "                res[mfs][topn][m][\"df_test_mae\"], res[mfs][topn][m][\"df_test_rmse\"], res[mfs][topn][m][\"df_test_r2\"]  \\\n",
    "                    = df_template.copy(), df_template.copy(), df_template.copy(), df_template.copy(), df_template.copy(), df_template.copy() \n",
    "    return res\n",
    "\n",
    " \n",
    "# comp_y_pred not comput gene error; only save y_predict valueï¼Œlater compute generic +gene specific 1:5 \n",
    "def comp_y_pred(p):\n",
    "    # usage: comp_y_pred(\"ENSG00000000419\") \n",
    "    if mfs == \"cosine\":\n",
    "        '''# use cosine similarity way to select topn , only use TRAIN set :  a better feature selection methods??'''\n",
    "        select=X_train.columns[cos_top[p]]\n",
    "\n",
    "    elif mfs == \"random\":\n",
    "        '''# random extract features'''             \n",
    "        idx = np.random.randint(X_train.shape[1], size=topn)\n",
    "        select = X_train.columns[idx]\n",
    "\n",
    "    else:\n",
    "        pass\n",
    "#     print(p, end=\" \")\n",
    "    X_val_select, X_train_select, y_val, y_train = X_val[select], X_train[select], Y_val[p], Y_train[p]\n",
    "    #'''fit model with selected features'''\n",
    "    my_model=model_dict[m].fit(X_train_select, y_train)\n",
    "    y_predict = my_model.predict(X_val_select)\n",
    "#     print(p)\n",
    "    \n",
    "    return y_predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['colon_86_2014_labelfree',\n",
       " 'prostate_65_2019_labelfree',\n",
       " 'lung_76_2020_labelfree',\n",
       " 'liver_62_2019_labelfree',\n",
       " 'brain_71_2017_labelfree',\n",
       " 'liver_318_2019_tmt',\n",
       " 'uterus_115_2020_tmt',\n",
       " 'lung_211_2020_tmt',\n",
       " 'lung_89_2020_tmt',\n",
       " 'colon_95_2019_tmt',\n",
       " 'renal_185_2019_tmt',\n",
       " 'brain_108_2021_tmt',\n",
       " 'pedbrain_188_2020_tmt',\n",
       " 'headneck_151_2021_tmt',\n",
       " 'pancrea_140_2021_tmt',\n",
       " 'lung_202_2021_tmt',\n",
       " 'breast_122_2020_tmt',\n",
       " 'breast_77_2016_itraq',\n",
       " 'ovary_119_2016_itraq',\n",
       " 'stomach_80_2019_itraq']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colon_86_2014_labelfree (86, 14959) (86, 2244) (68, 14959) (18, 14959) (68, 2244) (18, 2244)\n",
      "[5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 200, 1000, 5000, 14959]\n",
      "prepare training set.\n",
      "prepare test set.\n",
      "Sat Oct  2 22:55:57 2021 random-- 5----- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 22:56:42 2021 random-- 5----- Lasso-----:  training split. 1 2 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/public/home/test1/soft/anaconda3/envs/py3.7.3/lib/python3.7/site-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/public/home/test1/soft/anaconda3/envs/py3.7.3/lib/python3.7/site-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4 5 test set. done.\n",
      "Sat Oct  2 22:57:28 2021 random-- 5----- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 22:58:16 2021 random-- 5----- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 22:59:03 2021 random-- 5----- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 22:59:49 2021 random-- 5----- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:01:32 2021 random-- 10---- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:02:18 2021 random-- 10---- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:03:05 2021 random-- 10---- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:03:54 2021 random-- 10---- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:04:42 2021 random-- 10---- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:05:29 2021 random-- 10---- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:07:14 2021 random-- 15---- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:08:02 2021 random-- 15---- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:08:49 2021 random-- 15---- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:09:39 2021 random-- 15---- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:10:27 2021 random-- 15---- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:11:15 2021 random-- 15---- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:13:04 2021 random-- 20---- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:13:52 2021 random-- 20---- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:14:40 2021 random-- 20---- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:15:33 2021 random-- 20---- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:16:22 2021 random-- 20---- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:17:10 2021 random-- 20---- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:19:01 2021 random-- 25---- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:19:50 2021 random-- 25---- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:20:39 2021 random-- 25---- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:21:37 2021 random-- 25---- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:22:25 2021 random-- 25---- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:23:14 2021 random-- 25---- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:25:06 2021 random-- 30---- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:25:56 2021 random-- 30---- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:26:46 2021 random-- 30---- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:27:46 2021 random-- 30---- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:28:35 2021 random-- 30---- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:29:23 2021 random-- 30---- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:31:19 2021 random-- 35---- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:32:07 2021 random-- 35---- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:32:56 2021 random-- 35---- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:33:57 2021 random-- 35---- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:34:48 2021 random-- 35---- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:35:36 2021 random-- 35---- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:37:32 2021 random-- 40---- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:38:20 2021 random-- 40---- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:39:08 2021 random-- 40---- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:40:10 2021 random-- 40---- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:40:59 2021 random-- 40---- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:41:50 2021 random-- 40---- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:43:46 2021 random-- 45---- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:44:35 2021 random-- 45---- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:45:26 2021 random-- 45---- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:46:27 2021 random-- 45---- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:47:17 2021 random-- 45---- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:48:06 2021 random-- 45---- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:50:06 2021 random-- 50---- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:50:58 2021 random-- 50---- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:51:47 2021 random-- 50---- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:52:50 2021 random-- 50---- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:53:41 2021 random-- 50---- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:54:31 2021 random-- 50---- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:56:32 2021 random-- 200--- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:57:22 2021 random-- 200--- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:58:16 2021 random-- 200--- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sat Oct  2 23:59:22 2021 random-- 200--- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:00:11 2021 random-- 200--- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:01:04 2021 random-- 200--- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:03:49 2021 random-- 1000-- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:04:42 2021 random-- 1000-- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:05:47 2021 random-- 1000-- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:07:07 2021 random-- 1000-- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:07:58 2021 random-- 1000-- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:08:51 2021 random-- 1000-- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:15:40 2021 random-- 5000-- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:16:43 2021 random-- 5000-- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:18:41 2021 random-- 5000-- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:21:43 2021 random-- 5000-- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:22:45 2021 random-- 5000-- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:23:51 2021 random-- 5000-- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:50:30 2021 cosine-- 5----- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:51:20 2021 cosine-- 5----- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:52:13 2021 cosine-- 5----- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:53:05 2021 cosine-- 5----- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:53:55 2021 cosine-- 5----- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:54:44 2021 cosine-- 5----- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:56:31 2021 cosine-- 10---- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:57:25 2021 cosine-- 10---- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:58:15 2021 cosine-- 10---- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:59:08 2021 cosine-- 10---- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 00:59:58 2021 cosine-- 10---- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:00:52 2021 cosine-- 10---- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:02:41 2021 cosine-- 15---- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:03:31 2021 cosine-- 15---- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:04:22 2021 cosine-- 15---- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:05:16 2021 cosine-- 15---- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:06:15 2021 cosine-- 15---- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:07:07 2021 cosine-- 15---- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:08:59 2021 cosine-- 20---- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:09:51 2021 cosine-- 20---- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:10:43 2021 cosine-- 20---- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:11:47 2021 cosine-- 20---- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:12:38 2021 cosine-- 20---- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:13:30 2021 cosine-- 20---- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:15:22 2021 cosine-- 25---- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:16:13 2021 cosine-- 25---- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:17:04 2021 cosine-- 25---- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:18:10 2021 cosine-- 25---- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:19:02 2021 cosine-- 25---- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:19:53 2021 cosine-- 25---- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:21:48 2021 cosine-- 30---- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:22:39 2021 cosine-- 30---- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:23:30 2021 cosine-- 30---- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:24:39 2021 cosine-- 30---- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:25:29 2021 cosine-- 30---- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:26:21 2021 cosine-- 30---- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:28:18 2021 cosine-- 35---- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:29:10 2021 cosine-- 35---- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:30:02 2021 cosine-- 35---- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:31:10 2021 cosine-- 35---- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:32:03 2021 cosine-- 35---- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:32:55 2021 cosine-- 35---- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:34:55 2021 cosine-- 40---- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:35:47 2021 cosine-- 40---- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:36:39 2021 cosine-- 40---- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:37:49 2021 cosine-- 40---- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:38:41 2021 cosine-- 40---- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:39:33 2021 cosine-- 40---- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:41:34 2021 cosine-- 45---- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:42:26 2021 cosine-- 45---- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:43:19 2021 cosine-- 45---- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:44:24 2021 cosine-- 45---- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:45:20 2021 cosine-- 45---- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:46:13 2021 cosine-- 45---- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:48:15 2021 cosine-- 50---- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:49:09 2021 cosine-- 50---- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:50:02 2021 cosine-- 50---- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:51:09 2021 cosine-- 50---- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:52:02 2021 cosine-- 50---- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:53:02 2021 cosine-- 50---- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:55:05 2021 cosine-- 200--- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:55:59 2021 cosine-- 200--- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:56:53 2021 cosine-- 200--- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:58:02 2021 cosine-- 200--- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:58:54 2021 cosine-- 200--- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 01:59:49 2021 cosine-- 200--- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 02:02:44 2021 cosine-- 1000-- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 02:03:39 2021 cosine-- 1000-- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 02:04:44 2021 cosine-- 1000-- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 02:06:07 2021 cosine-- 1000-- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 02:07:03 2021 cosine-- 1000-- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 02:08:00 2021 cosine-- 1000-- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 02:14:52 2021 cosine-- 5000-- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 02:15:59 2021 cosine-- 5000-- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 02:18:16 2021 cosine-- 5000-- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 02:21:21 2021 cosine-- 5000-- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 02:22:22 2021 cosine-- 5000-- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 02:23:30 2021 cosine-- 5000-- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 02:49:58 2021 cosine-- 14959- LR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 02:51:44 2021 cosine-- 14959- Lasso-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 02:56:59 2021 cosine-- 14959- HR--------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 03:06:13 2021 cosine-- 14959- Ridge-----:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 03:07:24 2021 cosine-- 14959- SVR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "Sun Oct  3 03:09:21 2021 cosine-- 14959- RFR-------:  training split. 1 2 3 4 5 test set. done.\n",
      "CPU times: user 38min 22s, sys: 58min 34s, total: 1h 36min 56s\n",
      "Wall time: 5h 29min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# df_summary = df_summary.reindex(list(dict_dataset.keys()))\n",
    "\n",
    "run_cross_validation = True\n",
    "run_test = True\n",
    "\n",
    "list_model = list(model_dict.keys())\n",
    "\n",
    "for mykey in [\"colon_86_2014_labelfree\"]:\n",
    "# for mykey in datalist[13:14]: \n",
    "    # data transformåˆ°mean=0, std=1\n",
    "    X = dict_dataset[mykey][\"RNA\"].transform(lambda x: (x-x.mean())/x.std(), axis=1).round(3).transpose()\n",
    "    Y = dict_dataset[mykey][\"protein\"].transform(lambda x: (x-x.mean())/x.std(), axis=1).round(3).transpose()\n",
    "\n",
    "    X_use, X_test, Y_use, Y_test = train_test_split(X, Y, test_size=0.2, random_state=123, shuffle=True)\n",
    "    print(mykey, X.shape, Y.shape, X_use.shape, X_test.shape,  Y_use.shape, Y_test.shape)\n",
    "    my_list_topn = list_topn + [X.shape[1]]\n",
    "    print(my_list_topn)\n",
    "    \n",
    "    df_template = pd.DataFrame(index= Y_use.columns, columns= range(N))\n",
    "    res = create_res(my_list_topn)\n",
    "    \n",
    "    ############## 1. rank all features by a method, run once for the data set, use the maxtrix later\n",
    "    # split i have its own feature rankings\n",
    "    if run_cross_validation == True:\n",
    "        print(\"prepare training set.\")\n",
    "        # cross-validation on train set; \n",
    "        kf = KFold(n_splits=N, random_state=1, shuffle=True)\n",
    "        dict_cos_rank_val = dict.fromkeys(range(N)) \n",
    "\n",
    "        i = 0\n",
    "        for train_index, test_index in kf.split(Y_use): \n",
    "            X_train, X_val = X_use.iloc[train_index],  X_use.iloc[test_index]\n",
    "            Y_train, Y_val = Y_use.iloc[train_index],  Y_use.iloc[test_index]\n",
    "\n",
    "            cos = pd.DataFrame(data=metrics.pairwise.cosine_similarity(X=X_train.transpose(), Y=Y_train.transpose(), dense_output=True))\n",
    "            dict_cos_rank_val[i] = abs(cos).rank(axis=0, ascending=False).astype(int)\n",
    "            i = i +1\n",
    "\n",
    "    # test\n",
    "    if run_test == True:\n",
    "        print(\"prepare test set.\")\n",
    "        cos = pd.DataFrame(data=metrics.pairwise.cosine_similarity(X=X_use.transpose(), Y=Y_use.transpose(), dense_output=True))\n",
    "        dict_cos_rank_test = abs(cos).rank(axis=0, ascending=False).astype(int)\n",
    "    \n",
    "    ############### 2. cross-validaton model fit and evaluate with test\n",
    "    for mfs in method_feature_select[:2]:\n",
    "        for topn in my_list_topn:\n",
    "            if (topn == X.shape[1] ) & (mfs =='random'): ### random feature skip all features\n",
    "                continue\n",
    "            for m in list_model:\n",
    "                print(time.ctime(), mfs.ljust(8,'-'), str(topn).ljust(6,'-'), m.ljust(10,'-'), end=\":  \")\n",
    "#                 continue\n",
    "                if run_cross_validation:\n",
    "                    start =time.time()\n",
    "                    print(\"training split.\", end=\" \")\n",
    "\n",
    "                    i = 0\n",
    "                    for train_index, test_index in kf.split(Y_use): # random trials to stablize errors\n",
    "                        X_train, X_val = X_use.iloc[train_index],  X_use.iloc[test_index]\n",
    "                        Y_train, Y_val = Y_use.iloc[train_index], Y_use.iloc[test_index]\n",
    "                        \n",
    "                        cos_top = (dict_cos_rank_val[i] <= topn)\n",
    "                        cos_top.columns = Y_train.columns\n",
    "                        with Pool(nCPU) as pool:      \n",
    "                            y_pred_in_rows = pool.map(comp_y_pred, Y_train.columns)\n",
    "                        \n",
    "                        y_pred =  pd.DataFrame(data=y_pred_in_rows, index=Y_val.columns, columns= Y_val.index).transpose().round(3)\n",
    "                        res[mfs][topn][m][\"y_pred_val\"][i]           = y_pred\n",
    "                        res[mfs][topn][m][\"df_val_mae\" ].loc[:, i] = [ metrics.mean_absolute_error(Y_val[g], y_pred[g]) for g in Y_use.columns]\n",
    "                        res[mfs][topn][m][\"df_val_rmse\"].loc[:, i] = [ np.sqrt(metrics.mean_squared_error(Y_val[g], y_pred[g])) for g in Y_use.columns]\n",
    "                        res[mfs][topn][m][\"df_val_r2\"].loc[:, i]      = [ np.corrcoef(Y_val[g], y_pred[g])[1,0] for g in Y_use.columns]\n",
    "                        i = i + 1;  print(i, end=\" \");  # end for split i\n",
    "                    # end:  N fold\n",
    "                    res[mfs][topn][\"time\"].loc[m, \"val\"] =  int(time.time() - start)\n",
    "                    \n",
    "                if  run_test:\n",
    "                    start =time.time()\n",
    "                    print(\"test set.\", end=\" \")\n",
    "\n",
    "                    X_train, X_val, Y_train, Y_val = deepcopy(X_use),  deepcopy(X_test), deepcopy(Y_use),  deepcopy(Y_test)\n",
    "\n",
    "                    cos_top = (dict_cos_rank_test <= topn)\n",
    "                    cos_top.columns = Y_train.columns\n",
    "                    with Pool(nCPU) as pool:      \n",
    "                        y_pred_in_rows = pool.map(comp_y_pred, Y_train.columns)\n",
    "\n",
    "                    y_pred =  pd.DataFrame(data=y_pred_in_rows, index=Y_val.columns, columns=Y_val.index).transpose().round(3)\n",
    "\n",
    "                    res[mfs][topn][m][\"y_pred_test\"] = y_pred\n",
    "                    i = 0\n",
    "                    res[mfs][topn][m][\"df_test_mae\"].loc[:, i] = [ metrics.mean_absolute_error(Y_val[g], y_pred[g]) for g in Y_use.columns]\n",
    "                    res[mfs][topn][m][\"df_test_rmse\"].loc[:, i] = [ np.sqrt(metrics.mean_squared_error(Y_val[g], y_pred[g])) for g in Y_use.columns]\n",
    "                    res[mfs][topn][m][\"df_test_r2\"].loc[:, i] = [ np.corrcoef(Y_val[g], y_pred[g])[1,0] for g in Y_use.columns]\n",
    "                    res[mfs][topn][\"time\"].loc[m, \"test\"] =  int(time.time() - start)\n",
    "                    \n",
    "                print(\"done.\")\n",
    "                \n",
    "    with open('/public/home/test1/mydata/proteome/data/res_' + mykey + time.strftime(\"%Y%m%d-%H%M\")+'.pkl', 'wb') as f:   \n",
    "        pickle.dump( [res],  f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### random all == cosine all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>193</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>547</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HR</th>\n",
       "      <td>1492</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>251</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>299</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFR</th>\n",
       "      <td>12260</td>\n",
       "      <td>3220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         val  test\n",
       "LR       193    45\n",
       "Lasso    547   125\n",
       "HR      1492   425\n",
       "Ridge    251    39\n",
       "SVR      299    79\n",
       "RFR    12260  3220"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[mfs][topn][\"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## summary for a fixed topN, average meric of all genes\n",
    "mfs = \"cosine\"\n",
    "print(mfs)\n",
    "# my_list_topn = list_topn\n",
    "for topN in my_list_topn:\n",
    "    print(topN, end=\"_\")\n",
    "    res[mfs][topN][\"summary\"].index.name = mfs + '_' +str(topN)\n",
    "    for m in model_dict:\n",
    "        for my_metric in [\"mae\",\"rmse\",\"r2\"]:\n",
    "\n",
    "            res[mfs][topN][\"summary\"].loc[m, my_metric + \"_val_mean\"] =  res[mfs][topN][m][\"df_val_\"+ my_metric].mean(axis=1).mean()\n",
    "\n",
    "            res[mfs][topN][\"summary\"].loc[m, my_metric + \"_val\"] =  \\\n",
    "                \"%.3f\" % res[mfs][topN][\"summary\"].loc[m, my_metric + \"_val_mean\"] +  \"Â±\" + \\\n",
    "                \"%.3f\" % res[mfs][topN][m][\"df_val_\"+ my_metric].mean(axis=1).std()\n",
    "\n",
    "            res[mfs][topN][\"summary\"].loc[m, my_metric + \"_test_mean\"] =  res[mfs][topN][m][\"df_test_\"+ my_metric].mean(axis=1).mean()\n",
    "\n",
    "            res[mfs][topN][\"summary\"].loc[m, my_metric + \"_test\"] =  \\\n",
    "                \"%.3f\" % res[mfs][topN][\"summary\"].loc[m, my_metric + \"_test_mean\"] +  \"Â±\" + \\\n",
    "                \"%.3f\" % res[mfs][topN][m][\"df_test_\"+ my_metric].mean(axis=1).std()\n",
    "\n",
    "res[mfs][topN][\"summary\"].iloc[:, 9:].astype(np.float).style.highlight_min(axis=0)\n",
    "# 0.781Â±0.142\t0.997Â±0.187\t0.158Â±0.238"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5_10_15_20_25_30_35_40_45_50_200_1000_5000_10163_"
     ]
    }
   ],
   "source": [
    "## summary for models at different feature length\n",
    "# my_list_topn = list_topn\n",
    "df_template = pd.DataFrame(index = list(model_dict.keys()),  columns = my_list_topn)\n",
    "df_time, df_mae, df_rmse, df_r2= df_template.copy(),df_template.copy(), df_template.copy(), df_template.copy() \n",
    "mfs = \"cosine\"\n",
    "# mfs = \"random\"\n",
    "for topN in my_list_topn:\n",
    "    print(topN, end=\"_\")\n",
    "    \n",
    "    df_time.loc[:, topN] = res[mfs][topN][\"time\"].loc[:,\"test\"]\n",
    "    df_mae.loc[:, topN] = res[mfs][topN][\"summary\"].loc[:, \"mae_test_mean\"]\n",
    "    df_rmse.loc[:, topN] = res[mfs][topN][\"summary\"].loc[:, \"rmse_test_mean\"]\n",
    "    df_r2.loc[:, topN] = res[mfs][topN][\"summary\"].loc[:, \"r2_test_mean\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "      <th>10</th>\n",
       "      <th>15</th>\n",
       "      <th>20</th>\n",
       "      <th>25</th>\n",
       "      <th>30</th>\n",
       "      <th>35</th>\n",
       "      <th>40</th>\n",
       "      <th>45</th>\n",
       "      <th>50</th>\n",
       "      <th>200</th>\n",
       "      <th>1000</th>\n",
       "      <th>5000</th>\n",
       "      <th>10163</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>0.459370</td>\n",
       "      <td>0.461265</td>\n",
       "      <td>0.453990</td>\n",
       "      <td>0.442301</td>\n",
       "      <td>0.429772</td>\n",
       "      <td>0.414981</td>\n",
       "      <td>0.398039</td>\n",
       "      <td>0.382294</td>\n",
       "      <td>0.365553</td>\n",
       "      <td>0.348935</td>\n",
       "      <td>0.349120</td>\n",
       "      <td>0.464322</td>\n",
       "      <td>0.484082</td>\n",
       "      <td>0.484515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>0.462317</td>\n",
       "      <td>0.473300</td>\n",
       "      <td>0.477296</td>\n",
       "      <td>0.477022</td>\n",
       "      <td>0.476862</td>\n",
       "      <td>0.475652</td>\n",
       "      <td>0.473417</td>\n",
       "      <td>0.471808</td>\n",
       "      <td>0.469414</td>\n",
       "      <td>0.467784</td>\n",
       "      <td>0.448773</td>\n",
       "      <td>0.451986</td>\n",
       "      <td>0.467608</td>\n",
       "      <td>0.472986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HR</th>\n",
       "      <td>0.460767</td>\n",
       "      <td>0.462186</td>\n",
       "      <td>0.454125</td>\n",
       "      <td>0.441155</td>\n",
       "      <td>0.428510</td>\n",
       "      <td>0.412761</td>\n",
       "      <td>0.395502</td>\n",
       "      <td>0.377796</td>\n",
       "      <td>0.358206</td>\n",
       "      <td>0.338837</td>\n",
       "      <td>0.363951</td>\n",
       "      <td>0.462043</td>\n",
       "      <td>0.477458</td>\n",
       "      <td>0.476920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>0.461118</td>\n",
       "      <td>0.465800</td>\n",
       "      <td>0.461584</td>\n",
       "      <td>0.452875</td>\n",
       "      <td>0.444051</td>\n",
       "      <td>0.433192</td>\n",
       "      <td>0.420978</td>\n",
       "      <td>0.409683</td>\n",
       "      <td>0.397792</td>\n",
       "      <td>0.387499</td>\n",
       "      <td>0.362935</td>\n",
       "      <td>0.464643</td>\n",
       "      <td>0.484095</td>\n",
       "      <td>0.484571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>0.425585</td>\n",
       "      <td>0.439023</td>\n",
       "      <td>0.446553</td>\n",
       "      <td>0.449984</td>\n",
       "      <td>0.453421</td>\n",
       "      <td>0.455775</td>\n",
       "      <td>0.457474</td>\n",
       "      <td>0.458747</td>\n",
       "      <td>0.460272</td>\n",
       "      <td>0.461518</td>\n",
       "      <td>0.467451</td>\n",
       "      <td>0.462425</td>\n",
       "      <td>0.458914</td>\n",
       "      <td>0.457214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RFR</th>\n",
       "      <td>0.450003</td>\n",
       "      <td>0.469952</td>\n",
       "      <td>0.477901</td>\n",
       "      <td>0.481831</td>\n",
       "      <td>0.484714</td>\n",
       "      <td>0.486606</td>\n",
       "      <td>0.487644</td>\n",
       "      <td>0.489023</td>\n",
       "      <td>0.489835</td>\n",
       "      <td>0.490968</td>\n",
       "      <td>0.495729</td>\n",
       "      <td>0.494604</td>\n",
       "      <td>0.490995</td>\n",
       "      <td>0.489060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          5         10        15        20        25        30        35     \\\n",
       "LR     0.459370  0.461265  0.453990  0.442301  0.429772  0.414981  0.398039   \n",
       "Lasso  0.462317  0.473300  0.477296  0.477022  0.476862  0.475652  0.473417   \n",
       "HR     0.460767  0.462186  0.454125  0.441155  0.428510  0.412761  0.395502   \n",
       "Ridge  0.461118  0.465800  0.461584  0.452875  0.444051  0.433192  0.420978   \n",
       "SVR    0.425585  0.439023  0.446553  0.449984  0.453421  0.455775  0.457474   \n",
       "RFR    0.450003  0.469952  0.477901  0.481831  0.484714  0.486606  0.487644   \n",
       "\n",
       "          40        45        50        200       1000      5000      10163  \n",
       "LR     0.382294  0.365553  0.348935  0.349120  0.464322  0.484082  0.484515  \n",
       "Lasso  0.471808  0.469414  0.467784  0.448773  0.451986  0.467608  0.472986  \n",
       "HR     0.377796  0.358206  0.338837  0.363951  0.462043  0.477458  0.476920  \n",
       "Ridge  0.409683  0.397792  0.387499  0.362935  0.464643  0.484095  0.484571  \n",
       "SVR    0.458747  0.460272  0.461518  0.467451  0.462425  0.458914  0.457214  \n",
       "RFR    0.489023  0.489835  0.490968  0.495729  0.494604  0.490995  0.489060  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_r2.astype(np.float)#.style.highlight_max(axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3.7.3]",
   "language": "python",
   "name": "conda-env-py3.7.3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
